{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03311242-6073-4e18-81ab-0a0165a49f88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/tksakaki/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /Users/tksakaki/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce672ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Chapter04から使用するテキストデータをコピーする（事前にChapter04/4.2.1_classification_clustering.ipynbを実行してください）\n",
    "!cp -r ../Chapter04/text ./\n",
    "!cp -r ../Chapter04/sisyou_db ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c19d5c-773d-45dd-9375-0d4d24f7694f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error loading config: Serde error: key must be a string at line 4 column 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matcher\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mja_ginza\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m matcher \u001b[38;5;241m=\u001b[39m Matcher(nlp\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msisyou_db/sisyou_db_h29_01.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, skiprows\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/util.py:420\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/util.py:453\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/ja_ginza/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/util.py:615\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[0;32m--> 615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/util.py:488\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    486\u001b[0m overrides \u001b[38;5;241m=\u001b[39m dict_to_dot(config)\n\u001b[1;32m    487\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[0;32m--> 488\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/util.py:525\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[0;34m(config, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[1;32m    524\u001b[0m lang_cls \u001b[38;5;241m=\u001b[39m get_lang_class(nlp_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 525\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mlang_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/language.py:1752\u001b[0m, in \u001b[0;36mLanguage.from_config\u001b[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1746\u001b[0m warn_if_jupyter_cupy()\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;66;03m# Note that we don't load vectors here, instead they get loaded explicitly\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;66;03m# inside stuff like the spacy train function. If we loaded them here,\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;66;03m# then we would load them twice at runtime: once when we make from config,\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# and then again when we load from disk.\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mlang_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m after_creation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1754\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m after_creation(nlp)\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/language.py:190\u001b[0m, in \u001b[0;36mLanguage.__init__\u001b[0;34m(self, vocab, max_length, meta, create_tokenizer, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     tokenizer_cfg \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m    189\u001b[0m     create_tokenizer \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mresolve(tokenizer_cfg)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_error_handler \u001b[38;5;241m=\u001b[39m raise_error\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/lang/ja/__init__.py:38\u001b[0m, in \u001b[0;36mcreate_tokenizer.<locals>.japanese_tokenizer_factory\u001b[0;34m(nlp)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjapanese_tokenizer_factory\u001b[39m(nlp):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mJapaneseTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/lang/ja/__init__.py:47\u001b[0m, in \u001b[0;36mJapaneseTokenizer.__init__\u001b[0;34m(self, vocab, split_mode)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab \u001b[38;5;241m=\u001b[39m vocab\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_mode \u001b[38;5;241m=\u001b[39m split_mode\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtry_sudachi_import\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# if we're using split mode A we don't need subtokens\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_subtokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (split_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m split_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv/kspub_ds_text_analytics_ver05/.venv/lib/python3.9/site-packages/spacy/lang/ja/__init__.py:244\u001b[0m, in \u001b[0;36mtry_sudachi_import\u001b[0;34m(split_mode)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msudachipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dictionary, tokenizer\n\u001b[1;32m    238\u001b[0m     split_mode \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m: tokenizer\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mSplitMode\u001b[38;5;241m.\u001b[39mA,\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenizer\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mSplitMode\u001b[38;5;241m.\u001b[39mA,\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenizer\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mSplitMode\u001b[38;5;241m.\u001b[39mB,\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenizer\u001b[38;5;241m.\u001b[39mTokenizer\u001b[38;5;241m.\u001b[39mSplitMode\u001b[38;5;241m.\u001b[39mC,\n\u001b[1;32m    243\u001b[0m     }[split_mode]\n\u001b[0;32m--> 244\u001b[0m     tok \u001b[38;5;241m=\u001b[39m \u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(mode\u001b[38;5;241m=\u001b[39msplit_mode)\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tok\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mException\u001b[0m: Error loading config: Serde error: key must be a string at line 4 column 5"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "df = pd.read_excel(\"sisyou_db/sisyou_db_h29_01.xlsx\", skiprows=[1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b81afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patterns = [[{\"POS\": \"NOUN\"}] * n for n in [2,3,4]]\n",
    "\n",
    "## GiNZA 5.0.X\n",
    "for pattern in patterns:\n",
    "    name = f'noun_phrase_{len(pattern)}'\n",
    "    matcher.add(name, [pattern])\n",
    "\n",
    "## GiNZA 4.0.X\n",
    "#for pattern in patterns:\n",
    "#     name = f'noun_phrase_{len(pattern)}'\n",
    "#     matcher.add(name, None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776f281b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "工場内で、鉄骨階段（仮組）高さ2m50cmに手摺を仮組立作業中、足を滑らせて転倒し、顔面を強打して骨折し、右脇腹肋骨も骨折した。\n",
      "noun_phrase_2 工場内\n",
      "noun_phrase_2 鉄骨階段\n",
      "noun_phrase_2 仮組\n",
      "noun_phrase_2 右脇腹\n",
      "noun_phrase_3 右脇腹肋骨\n",
      "noun_phrase_2 脇腹肋骨\n",
      "================================================================================\n",
      "倉庫の出入口の階段を荷物（冷凍商品15kgぐらい）を持って下りる際に、階段が凍っていて滑って転倒し、階段を転げ落ち（4段位）、持っていた荷物を足に落としてしまい、右足の腓骨を骨折した。\n",
      "noun_phrase_2 出入口\n",
      "noun_phrase_2 冷凍商品\n",
      "================================================================================\n",
      "道路の3車線の真ん中を走行中、左車線に侵入してしまい、走行中の大型ワンボックスカーと衝突し、首と左肩を痛め、回転性のめまいで入院し、痺れもある。\n",
      "noun_phrase_2 左車線\n",
      "noun_phrase_2 大型ワンボックスカー\n",
      "noun_phrase_2 回転性\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"工場内で、鉄骨階段（仮組）高さ2m50cmに手摺を仮組立作業中、足を滑らせて転倒し、顔面を強打して骨折し、右脇腹肋骨も骨折した。\",\n",
    "    \"倉庫の出入口の階段を荷物（冷凍商品15kgぐらい）を持って下りる際に、階段が凍っていて滑って転倒し、階段を転げ落ち（4段位）、持っていた荷物を足に落としてしまい、右足の腓骨を骨折した。\",\n",
    "    \"道路の3車線の真ん中を走行中、左車線に侵入してしまい、走行中の大型ワンボックスカーと衝突し、首と左肩を痛め、回転性のめまいで入院し、痺れもある。\"\n",
    "]\n",
    "\n",
    "for doc in nlp.pipe(texts):\n",
    "    print(doc.text)\n",
    "    for match_id, begin, end in matcher(doc):\n",
    "        print(nlp.vocab.strings[match_id], doc[begin:end])\n",
    "    print('='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4483a8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for doc in nlp.pipe(df[\"災害状況\"]):\n",
    "    nps = [doc[begin:end].text for _, begin, end in matcher(doc)]\n",
    "    counter.update(nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406f02ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count word\n",
      "工場内\t164\n",
      "終了後\t67\n",
      "工事現場\t56\n",
      "段目\t53\n",
      "倉庫内\t49\n",
      "作業台\t43\n",
      "配達中\t37\n",
      "歩行中\t37\n",
      "配達先\t32\n",
      "当社工場\t30\n",
      "大腿部\t29\n",
      "右手親指\t28\n",
      "業務中\t28\n",
      "利用者宅\t27\n",
      "清掃中\t24\n",
      "右手中指\t23\n",
      "左手親指\t22\n",
      "右手人差し指\t22\n",
      "左手中指\t21\n",
      "tダンプ\t21\n",
      "当社工場内\t20\n",
      "m下\t20\n",
      "駐車場内\t20\n",
      "資材置場\t20\n",
      "ベルトコンベア\t20\n",
      "配膳車\t20\n",
      "ため足\t19\n",
      "作業時\t19\n",
      "カゴ車\t19\n",
      "作業終了\t19\n",
      "清掃作業中\t19\n",
      "左手薬指\t19\n",
      "お湯\t19\n",
      "厨房内\t19\n",
      "左手小指\t18\n",
      "tトラック\t18\n",
      "新築工事\t18\n",
      "作業終了後\t18\n",
      "被災労働者\t18\n",
      "左手人差し指\t17\n",
      "利用者様\t17\n",
      "お客様宅\t17\n",
      "重さ約\t17\n",
      "トラック荷台\t16\n",
      "朝刊配達\t16\n",
      "新聞配達\t16\n",
      "カゴ台車\t16\n",
      "荷台上\t14\n",
      "朝刊配達中\t14\n",
      "左足親指\t14\n",
      "右手小指\t14\n",
      "清掃作業\t14\n",
      "パワーゲート\t14\n",
      "カッターナイフ\t14\n",
      "H鋼\t14\n",
      "従事中\t13\n",
      "切断中\t13\n",
      "完了後\t13\n",
      "事業所内\t13\n",
      "介助中\t13\n",
      "作業現場\t13\n",
      "本社工場\t13\n",
      "場内\t12\n",
      "作業後\t12\n",
      "バックヤード\t12\n",
      "開口部\t12\n",
      "包装機\t12\n",
      "ミキサー車\t11\n",
      "玄関前\t11\n",
      "業務終了\t11\n",
      "業務終了後\t11\n",
      "反対側\t11\n",
      "敷地内駐車場\t11\n",
      "入所者\t11\n",
      "店舗内\t11\n",
      "製造工場\t10\n",
      "現場内\t10\n",
      "新築工事現場\t10\n",
      "ハンドル操作\t10\n",
      "入浴介助\t10\n",
      "右手薬指\t10\n",
      "左第\t10\n",
      "室内\t10\n",
      "階段下\t10\n",
      "解体工事\t10\n",
      "解体作業中\t10\n",
      "右大腿\t10\n",
      "ダンプ荷台\t9\n",
      "改修工事\t9\n",
      "対向車線\t9\n",
      "路面凍結\t9\n",
      "左大腿\t9\n",
      "切断作業\t9\n",
      "新聞配達中\t9\n",
      "包装室\t9\n",
      "cm程度\t9\n",
      "圧迫骨折\t9\n",
      "加工中\t9\n",
      "天井クレーン\t9\n",
      "店舗厨房\t9\n",
      "プラスチック製\t9\n",
      "交換作業\t9\n",
      "安全カバー\t9\n",
      "右大腿部\t9\n",
      "送迎車\t9\n",
      "会社敷地内\t8\n",
      "右脇腹\t8\n",
      "洗車機\t8\n",
      "店舗駐車場\t8\n",
      "事務所内\t8\n",
      "右側面\t8\n",
      "左大腿部\t8\n",
      "バックルーム\t8\n",
      "従業員用\t8\n",
      "肋骨骨折\t8\n",
      "右手第\t8\n",
      "誘導警備\t8\n",
      "親指付け根\t8\n",
      "道路上\t8\n",
      "誘導中\t8\n",
      "資材置き場\t8\n",
      "ご利用者\t8\n",
      "左手指\t8\n",
      "左足甲\t8\n",
      "予想以上\t8\n",
      "最上部\t8\n",
      "足場板\t8\n",
      "左側面\t8\n",
      "右足甲\t8\n",
      "右肋骨\t8\n",
      "移動式\t8\n",
      "停車中\t8\n",
      "お茶\t8\n",
      "右前方\t7\n",
      "掃除中\t7\n",
      "横断歩道\t7\n",
      "加工室\t7\n",
      "右足膝\t7\n",
      "デイサービス利用者\t7\n",
      "信号待ち\t7\n",
      "切断機\t7\n",
      "t車\t7\n",
      "加工場\t7\n",
      "左足関節\t7\n",
      "右手甲\t7\n",
      "上腕部\t7\n",
      "入浴介助中\t7\n",
      "交通誘導\t7\n",
      "歩行困難\t7\n",
      "大型トラック\t7\n",
      "ハンドリフト\t7\n",
      "勤務中\t7\n",
      "加工作業中\t7\n",
      "進行方向\t7\n",
      "左足踵\t7\n",
      "転倒時\t7\n",
      "営業所構内\t7\n",
      "右足関節\t7\n",
      "入居者様\t7\n",
      "グレーチング\t7\n",
      "相手方車両\t7\n",
      "固定ピン\t7\n",
      "洗車場\t6\n",
      "凍結路面\t6\n",
      "相手車両\t6\n",
      "胸高直径\t6\n",
      "角パイプ\t6\n",
      "トラック後部\t6\n",
      "搬入口\t6\n",
      "配達業務\t6\n",
      "投入口\t6\n",
      "全体重\t6\n",
      "管理棟\t6\n",
      "半月板\t6\n",
      "右方向\t6\n",
      "注意不足\t6\n",
      "当社資材\t6\n",
      "車庫内\t6\n",
      "自社工場\t6\n",
      "左足くるぶし\t6\n",
      "左脇腹\t6\n",
      "運行中\t6\n",
      "左足小指\t6\n",
      "右足踵\t6\n",
      "外階段\t6\n",
      "交通誘導警備\t6\n",
      "警備中\t6\n",
      "反対車線\t6\n",
      "道路脇\t6\n",
      "号ライン\t6\n",
      "鉄板上\t6\n",
      "車両後部\t6\n",
      "製造ライン\t6\n",
      "直径約\t6\n",
      "自動二輪車\t6\n",
      "定位置\t6\n",
      "左肋骨\t6\n",
      "右足かかと\t6\n",
      "当社構内\t6\n",
      "処理室\t6\n"
     ]
    }
   ],
   "source": [
    "print('count word')\n",
    "for word, count in counter.most_common(200):\n",
    "     print('{}\\t{}'.format(word,count))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fb4418224693d26334f9c00586f18858debbdac5b5c2b9e8ec64f44f6ad2406"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
