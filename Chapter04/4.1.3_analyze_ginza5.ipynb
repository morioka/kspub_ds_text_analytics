{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c1bcae-fcb8-4251-817f-8a39f3f8591d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ginzaの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a453516-d487-43ac-b203-d98ae792eb2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 単語の共起"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010d067-873c-4299-bcfe-feb779ae2126",
   "metadata": {
    "tags": []
   },
   "source": [
    "単語が出現する頻度を単独で調べるだけでなく，単語間の関係を調べることもできる．\n",
    "共起を求める関数を定義し，題材の小説「影男」で共起を求めてみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312c58c6-cabb-4aab-8b8b-ef2d0c6f2c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "input_fn = 'text/kageotoko.corpus.txt'\n",
    "\n",
    "include_pos = ('NOUN', 'VERB', 'ADJ')\n",
    "stopwords = ('する', 'ある', 'ない', 'いう', 'もの', 'こと', 'よう', 'なる', 'ほう', 'いる', 'くる')\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6474dac3-f2cf-41a8-a9a3-269ccc532226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_words(sent, pos_tags, stopwords):\n",
    "    words = [token.lemma_ for token in sent\n",
    "             if token.pos_ in pos_tags and token.lemma_ not in stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bc3e75-bf49-40be-ace9-9359fe96d7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def count_cooccurrence(sents, token_length='{2,}'):\n",
    "    token_pattern=f'\\\\b\\\\w{token_length}\\\\b'\n",
    "    count_model = CountVectorizer(token_pattern=token_pattern)\n",
    "\n",
    "    X = count_model.fit_transform(sents)\n",
    "    words = count_model.get_feature_names_out()\n",
    "    word_counts = np.asarray(X.sum(axis=0)).reshape(-1)\n",
    "\n",
    "    X[X > 0] = 1 # limit to 1 occurrence in a document.\n",
    "    Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "    return words, word_counts, Xc, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8710c76-f690-4ecf-961a-7638a92f7019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk(lst, n):\n",
    "    \"\"\"\n",
    "    リストをn個ずつのサブリストに分割する。\n",
    "    \"\"\"\n",
    "    return [lst[i:i+n] for i in range(0, len(lst), n)]\n",
    "\n",
    "\n",
    "with open(input_fn, 'r') as f:\n",
    "    lines = [l.replace(\"\\n\",\"\") for l in f.readlines()]\n",
    "\n",
    "lst_texts = chunk(lines,100)\n",
    "sents = []\n",
    "list_sents = []\n",
    "for text in lst_texts:\n",
    "    doc = nlp(\" \".join(text))\n",
    "    sents.extend([' '.join(extract_words(sent, include_pos, stopwords))\n",
    "                  for sent in doc.sents])\n",
    "    list_sents.extend(doc.sents)\n",
    "\n",
    "words, _, Xc, X = count_cooccurrence(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6070dd5-a174-47df-b52d-1e922f0a0580",
   "metadata": {
    "tags": []
   },
   "source": [
    "共起頻度の高い順に10個表示する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386fd02a-acea-4d7f-a558-af11872d7bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22 (会社, 殺人)\n",
      " 18 (やる, 来る)\n",
      " 17 (さま, だんな)\n",
      " 16 (さん, じい)\n",
      " 16 (ひらく, ドア)\n",
      " 16 (世界, 地底)\n",
      " 13 (かける, 電話)\n",
      " 12 (いく, まま)\n",
      " 11 (いく, 出る)\n",
      " 11 (くちびる, 赤い)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter()\n",
    "\n",
    "for i, j in zip(*Xc.nonzero()):\n",
    "    if i >= j:\n",
    "        continue\n",
    "    counter[(i,j)] += Xc[i,j]\n",
    "\n",
    "for (i,j), c in counter.most_common(10):\n",
    "    print('{:>3d} ({}, {})'.format(c, words[i], words[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76c144-432e-4e23-8248-f9eb2f2d393b",
   "metadata": {
    "tags": []
   },
   "source": [
    "「世界」と「地底」が共起する原文を表示する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2788c2c8-7715-4bac-8d38-0153583ea50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2590: そういうおかたは、この地底世界へおつれすることさえむずかしい。\n",
      " 2660: かれはそこでは、いつものゆすりを行なう気にもならず、地底の主人公のちょびひげ紳士と親交を約して別れをつげ、地上世界に立ち帰った。\n",
      " 4690: むろん、地底世界のつづきなのだ。\n",
      " 4718: この地底世界に、それほどの巨資があるのであろうか。\n",
      " 4719: このまえにちょびひげがいっていたのでは、地底世界の女の数は百人ぐらいのはずであった。\n",
      " 4759: 　地上世界の見せ物でこんなことをやれば、すぐに種がわかってしまうが、地底の洞窟という好条件がある。\n",
      " 4789: 　洞窟にはいってから二時間あまり、黒いメフィストは時を忘れ、追われている身を忘れ、地上のいっさいの煩いを忘れ、艶樹の森と、地底世界をどよもす音楽と、歌声と、踊り狂う五面十脚の美しい怪獣とに、果てしもなく酔いしれていたが、ふと気がつくと、またしても、ただならぬ奇怪事が起こっていた。\n",
      " 4836: どうしてこの地底世界へ、警官がはいりこんできたのか。\n",
      " 4845: 地底世界の経営者が内通したのだろうか。\n",
      " 4955: すると、こういうおもしろい地底の世界を見せてくれた。\n",
      " 4964: 「それにしても、明智先生は、この地底の世界へははじめて来られたのでしょう。\n",
      " 4976: 　一方、ぼくは地底世界で、ちょっと荒療治をやった。\n",
      " 4980: 地底世界の様子が、あらましわかった。\n",
      " 4985: 　それから、ちょびひげを脅迫して、池のシリンダーを浮き上がらせ、待機していた十人の警官を地底世界に引き入れた。\n",
      " 5044:  この世の果て  　明智小五郎は、中村警部やその部下とともに、地底世界の入り口に近いいわゆる事務室にもどっていた。\n",
      " 5064: 二つの世界で、わたしの地底王国はいっぱいですよ」\n"
     ]
    }
   ],
   "source": [
    "def find_sentence_by_cooccurrence(X, idxs):\n",
    "    occur_flags = (X[:,idxs[0]] > 0)\n",
    "    for idx in idxs[1:]:\n",
    "        occur_flags = occur_flags.multiply(X[:,idx] > 0)\n",
    "    return occur_flags.nonzero()[0]\n",
    "\n",
    "sents_orig = list_sents\n",
    "words_lookup = {word: index for index, word in enumerate(words)}\n",
    "idxs = [words_lookup[word] for word in ['世界', '地底']]\n",
    "\n",
    "for i in find_sentence_by_cooccurrence(X, idxs):\n",
    "    print(\"{:>5d}: {}\".format(i, sents_orig[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
