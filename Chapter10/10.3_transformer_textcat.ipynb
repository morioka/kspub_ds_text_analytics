{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3ccbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Chapter04から使用するテキストデータをコピーする（事前にChapter04/Sentiment.ipynbを実行してください）\n",
    "!cp -r ../Chapter04/sisyou_db ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ec24aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like megagonlabs/transformers-ud-japanese-electra-base-ginza-510 is not the path to a directory containing a file named config.json.\n",
      "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
      "error Can't load the configuration of '/var/folders/n8/f5dk0msn63n2039s3mfg66wc0000gn/T/tmpxjq1k98_/config.json'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/var/folders/n8/f5dk0msn63n2039s3mfg66wc0000gn/T/tmpxjq1k98_/config.json' is the correct path to a directory containing a config.json file\n",
      "trying to download model from huggingface hub: megagonlabs/transformers-ud-japanese-electra-base-ginza-510 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a978f5ccd8424dbff04c03ce54f79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/815 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a5de435bbd4fb0be2bb0195cf7d217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/434M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "succeded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "\n",
    "## モデルのロード\n",
    "nlp = spacy.load(\"ja_ginza_electra\")\n",
    "data_dir = \"sisyou_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0939df3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sisyou_db/sisyou_db_h28_01.xlsx\n",
      "sisyou_db/sisyou_db_h28_02.xlsx\n",
      "sisyou_db/sisyou_db_h28_03.xlsx\n",
      "sisyou_db/sisyou_db_h28_04.xlsx\n",
      "sisyou_db/sisyou_db_h28_05.xlsx\n",
      "sisyou_db/sisyou_db_h28_06.xlsx\n",
      "sisyou_db/sisyou_db_h28_07.xlsx\n",
      "sisyou_db/sisyou_db_h28_08.xlsx\n",
      "sisyou_db/sisyou_db_h28_09.xlsx\n",
      "sisyou_db/sisyou_db_h28_10.xlsx\n",
      "sisyou_db/sisyou_db_h28_11.xlsx\n",
      "sisyou_db/sisyou_db_h28_12.xlsx\n",
      "sisyou_db/sisyou_db_h29_01.xlsx\n",
      "sisyou_db/sisyou_db_h29_02.xlsx\n",
      "sisyou_db/sisyou_db_h29_03.xlsx\n",
      "sisyou_db/sisyou_db_h29_04.xlsx\n",
      "sisyou_db/sisyou_db_h29_05.xlsx\n",
      "sisyou_db/sisyou_db_h29_06.xlsx\n",
      "sisyou_db/sisyou_db_h29_07.xlsx\n",
      "sisyou_db/sisyou_db_h29_08.xlsx\n",
      "sisyou_db/sisyou_db_h29_09.xlsx\n",
      "sisyou_db/sisyou_db_h29_10.xlsx\n",
      "sisyou_db/sisyou_db_h29_11.xlsx\n",
      "sisyou_db/sisyou_db_h29_12.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 1.労災データベースからのファイルダウンロード\n",
    "## 労働災害データベースからのダウンロードを下記で行っていますが、\n",
    "## 本NotebookでははChapter04からコピーしているため、ダウンロード自体は行われません。\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "years = [28, 29]\n",
    "months = list(range(1, 13))\n",
    "\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        file_name = f\"{data_dir}/sisyou_db_h{y}_{m:02d}.xlsx\"\n",
    "        print(file_name)\n",
    "        if not os.path.exists(file_name):\n",
    "            file_url = f\"https://anzeninfo.mhlw.go.jp/anzen/shisyo_xls/sisyou_db_h{y}_{m:02d}.xlsx\"\n",
    "            res = requests.get(file_url)\n",
    "            with open(file_name, 'wb') as f:\n",
    "                f.write(res.content)\n",
    "            time.sleep(2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11b1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 分類対象データの読み込み\n",
    "## 労災データの読み込み\n",
    "def read_rousai_db(data_dir, year_months):\n",
    "    dfs = []\n",
    "    for y, m in year_months:\n",
    "        file_name = f\"{data_dir}/sisyou_db_h{y}_{m:02d}.xlsx\"\n",
    "        df = pd.read_excel(file_name, skiprows=[1])\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_ret = pd.concat(dfs)\n",
    "    df_ret = df_ret.rename(columns={\"事故の型\": \"事故の型_コード\",\n",
    "                                    \"Unnamed: 20\": \"事故の型_名前\"})\n",
    "    return df_ret\n",
    "\n",
    "## 訓練データ・テストデータの読み込み\n",
    "year_months_train = [(28, m) for m in months]\n",
    "year_months_dev = [(29, 1)]\n",
    "year_months_test = [(29, 2)]\n",
    "df_train = read_rousai_db(data_dir, year_months_train)\n",
    "df_dev = read_rousai_db(data_dir, year_months_dev)\n",
    "df_test = read_rousai_db(data_dir, year_months_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47717aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['転倒', '墜落、転落', '動作の反動、無理な動作', 'はさまれ、巻き込まれ', '切れ、こすれ', '交通事故（道路）', '飛来、落下', '激突', '激突され', '高温・低温の物との接触']\n"
     ]
    }
   ],
   "source": [
    "# 3.分類クラスを頻度上位10クラス+それ以外の11クラスに絞り込み\n",
    "names = df_train[\"事故の型_名前\"].unique()\n",
    "top10_category = df_train[\"事故の型_名前\"].value_counts()[0:10].index.to_list()\n",
    "name2label = {name: top10_category.index(name) if name in top10_category else len(top10_category) for i, name in enumerate(names)}\n",
    "print(top10_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f378e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.spaCy Command Line Interface 用の訓練データ・テストデータのファイルを生成\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert_docs(df_target, dic_label):\n",
    "    list_docs = []\n",
    "    for index, entry in df_target.iterrows():\n",
    "        doc = nlp.make_doc(entry[\"災害状況\"])\n",
    "        for label,val in dic_label.items():\n",
    "            if(label == entry[\"事故の型_名前\"]):\n",
    "                doc.cats[str(val)] = 1\n",
    "            else:\n",
    "                doc.cats[str(val)] = 0\n",
    "\n",
    "        list_docs.append(doc)\n",
    "    return list_docs\n",
    "\n",
    "docs_train = convert_docs(df_train, name2label)\n",
    "doc_bin_train = DocBin(docs=docs_train)\n",
    "doc_bin_train.to_disk(\"./train_ja.spacy\")\n",
    "\n",
    "docs_dev = convert_docs(df_dev, name2label)\n",
    "doc_bin_dev = DocBin(docs=docs_dev)\n",
    "doc_bin_dev.to_disk(\"./dev_ja.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbf3a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "ginza_textcat.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train ginza_textcat.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
      "\u001b[38;5;2m✔ Created output directory: rousai_classifier\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: rousai_classifier\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-04-19 22:31:05,736] [INFO] Set up nlp object from config\n",
      "[2023-04-19 22:31:05,741] [INFO] Pipeline: ['textcat']\n",
      "[2023-04-19 22:31:05,743] [INFO] Created vocabulary\n",
      "[2023-04-19 22:31:05,744] [INFO] Finished initializing nlp object\n",
      "[2023-04-19 22:32:03,505] [INFO] Initialized pipeline components: ['textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.08        0.00    0.00\n",
      "  0     200         54.99        0.00    0.00\n",
      "  0     400         51.81        0.00    0.00\n",
      "  0     600         50.06        0.02    0.00\n",
      "  0     800         48.27        0.11    0.00\n",
      "  1    1000         46.54        0.40    0.00\n",
      "  1    1200         45.42        1.72    0.02\n",
      "  1    1400         43.46        3.47    0.03\n",
      "  1    1600         41.68        5.61    0.06\n",
      "  1    1800         41.44        8.33    0.08\n",
      "  2    2000         40.60       11.05    0.11\n",
      "  2    2200         37.66       13.53    0.14\n",
      "  2    2400         38.33       16.07    0.16\n",
      "  2    2600         38.34       18.69    0.19\n",
      "  3    2800         35.58       21.05    0.21\n",
      "  3    3000         34.99       23.29    0.23\n",
      "  3    3200         34.17       25.20    0.25\n",
      "  3    3400         34.23       27.09    0.27\n",
      "  3    3600         33.00       28.35    0.28\n",
      "  4    3800         33.09       29.57    0.30\n",
      "  4    4000         31.31       30.95    0.31\n",
      "  4    4200         31.26       31.89    0.32\n",
      "  4    4400         30.77       32.58    0.33\n",
      "  5    4600         31.31       33.45    0.33\n",
      "  5    4800         31.22       34.18    0.34\n",
      "  5    5000         29.98       34.73    0.35\n",
      "  5    5200         28.99       35.42    0.35\n",
      "  5    5400         28.90       35.79    0.36\n",
      "  6    5600         28.69       36.28    0.36\n",
      "  6    5800         28.41       36.74    0.37\n",
      "  6    6000         28.11       37.06    0.37\n",
      "  6    6200         27.46       37.27    0.37\n",
      "  7    6400         28.59       37.47    0.37\n",
      "  7    6600         28.80       37.81    0.38\n",
      "  7    6800         28.01       38.03    0.38\n",
      "  7    7000         27.05       38.24    0.38\n",
      "  7    7200         26.68       38.33    0.38\n",
      "  8    7400         27.03       38.57    0.39\n",
      "  8    7600         26.33       38.66    0.39\n",
      "  8    7800         26.60       38.83    0.39\n",
      "  8    8000         27.27       39.08    0.39\n",
      "  9    8200         25.81       39.31    0.39\n",
      "  9    8400         25.47       39.46    0.39\n",
      "  9    8600         25.59       39.78    0.40\n",
      "  9    8800         25.57       39.85    0.40\n",
      "  9    9000         25.64       40.01    0.40\n",
      " 10    9200         25.83       40.12    0.40\n",
      " 10    9400         25.52       40.38    0.40\n",
      " 10    9600         25.74       40.61    0.41\n",
      " 10    9800         24.80       40.74    0.41\n",
      " 11   10000         24.57       40.96    0.41\n",
      " 11   10200         25.00       40.92    0.41\n",
      " 11   10400         24.85       40.99    0.41\n",
      " 11   10600         25.23       41.03    0.41\n",
      " 11   10800         24.66       41.41    0.41\n",
      " 12   11000         24.30       41.50    0.41\n",
      " 12   11200         24.53       41.58    0.42\n",
      " 12   11400         23.51       41.68    0.42\n",
      " 12   11600         24.15       41.85    0.42\n",
      " 13   11800         23.70       42.05    0.42\n",
      " 13   12000         23.60       42.12    0.42\n",
      " 13   12200         23.82       42.25    0.42\n",
      " 13   12400         24.04       42.35    0.42\n",
      " 13   12600         23.11       42.53    0.43\n",
      " 14   12800         23.66       42.60    0.43\n",
      " 14   13000         23.62       42.62    0.43\n",
      " 14   13200         23.28       42.68    0.43\n",
      " 14   13400         24.02       42.72    0.43\n",
      " 15   13600         22.93       42.73    0.43\n",
      " 15   13800         23.29       42.94    0.43\n",
      " 15   14000         23.11       43.05    0.43\n",
      " 15   14200         22.69       42.95    0.43\n",
      " 15   14400         23.20       43.02    0.43\n",
      " 16   14600         23.78       43.11    0.43\n",
      " 16   14800         22.31       43.14    0.43\n",
      " 16   15000         22.37       43.07    0.43\n",
      " 16   15200         22.22       43.33    0.43\n",
      " 17   15400         23.13       43.25    0.43\n",
      " 17   15600         22.54       43.29    0.43\n",
      " 17   15800         23.39       43.37    0.43\n",
      " 17   16000         22.62       43.46    0.43\n",
      " 17   16200         22.59       43.52    0.44\n",
      " 18   16400         22.60       43.53    0.44\n",
      " 18   16600         22.90       43.53    0.44\n",
      " 18   16800         23.48       43.55    0.44\n",
      " 18   17000         22.90       43.56    0.44\n",
      " 19   17200         22.04       43.75    0.44\n",
      " 19   17400         22.27       43.74    0.44\n",
      " 19   17600         22.09       43.80    0.44\n",
      " 19   17800         22.90       43.75    0.44\n",
      " 19   18000         22.80       43.78    0.44\n",
      " 20   18200         22.23       43.75    0.44\n",
      " 20   18400         22.91       43.75    0.44\n",
      " 20   18600         22.04       43.73    0.44\n",
      " 20   18800         21.85       43.73    0.44\n",
      " 21   19000         21.56       43.75    0.44\n",
      " 21   19200         22.63       43.76    0.44\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "rousai_classifier/model-last\n"
     ]
    }
   ],
   "source": [
    "# 5.分類器の学習を実行 => 文書分類モデルを./rousai_classifier　に保存\n",
    "## configファイルの生成\n",
    "!python -m spacy init fill-config ./base_ginza_textcat.cfg ./ginza_textcat.cfg\n",
    "## 訓練の実行\n",
    "!python -m spacy train ./ginza_textcat.cfg --output ./rousai_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7843943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7373857767183154(1856/2517)\n"
     ]
    }
   ],
   "source": [
    "# 6.性能がベストだった文書分類モデルを読み込み、評価用データに適用\n",
    "nlp_best = spacy.load(\"rousai_classifier/model-best\")\n",
    "counter = 0\n",
    "prec = 0\n",
    "for index, entry in df_test.iterrows():\n",
    "    doc = nlp_best(entry[\"災害状況\"])\n",
    "    label = entry[\"事故の型_名前\"]\n",
    "\n",
    "    ## 1番スコアの高いクラスを予測値とする\n",
    "    for k,v in sorted(doc.cats.items(),key=lambda x:x[1],reverse=True):\n",
    "        toprank = int(k)\n",
    "        break\n",
    "    ## 評価用データのラベルを分類クラスIDに変換\n",
    "    answer = name2label[label]\n",
    "\n",
    "    if toprank == answer:\n",
    "        prec += 1\n",
    "    counter += 1\n",
    "\n",
    "print(\"{}({}/{})\".format(prec/counter,prec,counter))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e1ac54945653f64782d1c43377b083b039c98d0e8056a0d8c72aa29f61e062d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
